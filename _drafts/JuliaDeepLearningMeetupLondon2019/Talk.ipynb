{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlow and other tools for ML in Julia\n",
    "\n",
    "\n",
    "![](data:image/svg+xml;base64,<svg viewBox="0 0 2575 495" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><g fill-rule="nonzero"><path d="M199.243 264.837l66.414-38.537 65.594 38.537-65.594 37.716-66.414-36.896v-.82z" fill="#f6bd3a"/><path d="M0 150.867L265.657 0l197.602 112.33-65.594 113.97-132.008-75.433-199.243 113.15L0 150.867z" fill="#f6bd3a"/><path d="M199.243 415.703V340.27l65.594-37.717 66.414-37.716v75.433l-65.594 37.717v75.433l-66.414 38.537v-76.254zm0-150.866l-66.415-37.717-66.414 36.897v-75.434l199.243-113.15V226.3l-66.414 38.537zm197.602-76.254v-37.716l66.414-38.537.82 75.434-66.414 38.536-.82-37.717z" fill="#eb8c23"/><path d="M132.828 451.78V227.12l65.595-36.897.82 74.614 66.414 36.897v76.253l-66.414-35.257v149.227l-66.415-40.177zM32.798 244.34L0 224.66v-73.793l66.414 37.716v75.434l-33.617-19.678zm232.859-93.472V75.433l131.188 75.434.82 75.433-132.008-75.433z" fill="#e35a2b"/></g><path d="M636.747 169.726v282.83h-49.746v-282.83h-96.646v-48.797h243.038v48.797h-96.646z" fill="#ef6639" fill-rule="nonzero"/><path d="M898.006 272.54c4.263 15.16 4.35 35.115 4.036 37.643l-160.56 47.6c1.264 12.003.896 7.137 4.685 15.665 3.79 8.528 8.528 15.554 14.213 21.08 5.686 5.528 12 9.637 18.95 12.318a59.952 59.952 0 0 0 21.795 4.028c10.421 0 19.975-1.738 28.66-5.21 8.686-3.474 17.135-8.372 25.346-14.686l28.9 31.267c-11.053 10.424-23.374 18.479-36.955 24.161-13.579 5.686-29.844 8.528-48.797 8.528-14.528 0-28.344-2.842-41.453-8.528-13.108-5.685-24.555-14.055-34.347-25.11-9.79-11.054-17.53-24.633-23.212-40.743-5.686-16.106-8.531-34.424-8.531-54.955 0-21.16 2.687-39.795 8.054-55.901 5.371-16.11 12.794-29.612 22.269-40.507 9.475-10.897 20.922-19.187 34.347-24.873 13.423-5.685 28.187-8.528 44.296-8.528 17.686 0 33.084 3.316 46.19 9.948 13.107 6.632 24.005 15.636 32.689 27.004 8.687 11.371 15.163 24.638 19.425 39.798zm-46.656 11.243c-.632-8.529-6.519-18.967-11.38-25.457-4.455-5.958-10.846-10.77-17.764-13.502-7.264-2.871-17.133-4.096-25.82-3.713-16.294.714-34.418 6.348-43.57 18.927-9.149 12.575-11.668 33.724-11.334 56.533l109.868-32.788zm226.92 165.94V309.017c0-25.267-4.5-42.955-13.502-53.062-9.002-10.106-21.557-15.16-37.667-15.16-16.421 0-29.053 5.527-37.899 16.58-8.842 11.054-13.264 26.69-13.264 46.906v145.44h-48.796v-248.72h48.796v23.687c6.318-9.16 15.081-16.268 26.293-21.318 11.212-5.054 23.295-7.582 36.244-7.582 29.056 0 51.086 9.319 66.088 27.951 15.001 18.635 22.503 46.43 22.503 83.382v142.6h-48.796zm249.211-65.386c0 13.896-2.607 25.502-7.816 34.821-5.213 9.316-12.08 16.818-20.608 22.504-8.53 5.682-18.4 9.789-29.612 12.317-11.212 2.525-22.977 3.79-35.294 3.79-17.053 0-34.03-3.002-50.93-9.002-16.895-6-31.659-13.582-44.293-22.742l22.265-36.952c11.685 8.214 23.768 14.37 36.244 18.479 12.473 4.104 24.555 6.156 36.24 6.156 30.321 0 45.481-9.157 45.481-27.478 0-9.474-5.13-17.053-15.395-22.738-10.266-5.686-24.4-12.003-42.403-18.953-13.264-5.053-24.555-10.183-33.874-15.395-9.316-5.212-16.898-10.818-22.739-16.818-5.844-6.003-10.027-12.714-12.555-20.134-2.526-7.426-3.79-16.03-3.79-25.82 0-11.053 2.052-20.845 6.159-29.374a57.39 57.39 0 0 1 17.53-21.318c7.578-5.686 16.58-9.949 27.004-12.791 10.421-2.843 21.792-4.266 34.11-4.266 15.792 0 31.031 2.528 45.715 7.582 14.687 5.053 27.557 11.685 38.613 19.896l-21.319 37.428c-10.106-7.264-20.372-12.635-30.793-16.11-10.424-3.471-21.637-5.209-33.64-5.209-12 0-20.686 2.132-26.054 6.394-5.371 4.266-8.055 9.713-8.055 16.345 0 3.16.632 6.08 1.896 8.766 1.264 2.684 3.63 5.448 7.105 8.29 3.475 2.843 8.135 5.765 13.976 8.764 5.844 3.001 13.502 6.397 22.977 10.186 13.899 5.368 26.057 10.5 36.479 15.398 10.424 4.895 19.187 10.422 26.295 16.58 7.106 6.159 12.397 13.344 15.872 21.557 3.472 8.21 5.21 18.159 5.21 29.844v.003zm226.937-57.324c0 20.528-2.842 38.924-8.528 55.19-5.685 16.268-13.581 30.006-23.688 41.218-10.107 11.212-21.95 19.74-35.53 25.581-13.58 5.844-28.426 8.766-44.533 8.766-15.792 0-30.32-3.08-43.585-9.24-13.264-6.158-24.793-14.921-34.585-26.292-9.79-11.37-17.45-24.95-22.977-40.742-5.527-15.792-8.29-33.48-8.29-53.061 0-20.214 2.843-38.376 8.528-54.482 5.683-16.107 13.502-29.768 23.45-40.98 9.948-11.212 21.634-19.74 35.06-25.581 13.422-5.845 28.03-8.767 43.819-8.767 15.792 0 30.479 3.081 44.06 9.24a105.774 105.774 0 0 1 35.294 25.82c9.949 11.053 17.686 24.555 23.213 40.506 5.53 15.948 8.292 33.557 8.292 52.824zm-49.27 1.42c0-25.582-5.605-45.875-16.817-60.88-11.213-15-26.77-22.503-46.666-22.503-18.634 0-33.242 7.502-43.822 22.504-10.58 15.004-15.871 34.824-15.871 59.459 0 27.477 5.685 48.4 17.056 62.771 11.368 14.37 26.372 21.557 45.007 21.557 9.157 0 17.527-2.21 25.108-6.632 7.579-4.421 14.055-10.344 19.423-17.767 5.37-7.423 9.475-16.186 12.317-26.293 2.843-10.107 4.266-20.846 4.266-32.216zm206.557-72.958a82.576 82.576 0 0 0-16.58-6.632c-5.685-1.58-12.635-2.37-20.845-2.37-15.475 0-27.478 5.368-36.006 16.107-8.528 10.742-12.79 26.69-12.79 47.85v142.126h-48.8v-248.72h48.8v23.688c5.682-8.214 13.501-15.081 23.45-20.61 9.947-5.527 21.08-8.29 33.398-8.29 10.106 0 18.4.87 24.873 2.607 6.476 1.734 12.238 4.342 17.291 7.817l-12.79 46.427z" fill="#ef6639" fill-rule="nonzero"/><path d="M1793.665 169.726v86.698h95.226v48.794h-95.23v147.338h-49.74v-331.63h213.662v48.8h-163.918zm172.004 282.83V132.774l48.8-25.585v345.367h-48.8zm297.988-125.543c0 20.528-2.845 38.924-8.53 55.19-5.683 16.268-13.58 30.006-23.686 41.218-10.107 11.212-21.951 19.74-35.533 25.581-13.581 5.844-28.427 8.766-44.533 8.766-15.792 0-30.32-3.08-43.585-9.24-13.264-6.158-24.793-14.921-34.585-26.292-9.79-11.37-17.45-24.95-22.977-40.742-5.527-15.792-8.29-33.48-8.29-53.061 0-20.214 2.842-38.376 8.528-54.482 5.685-16.107 13.502-29.768 23.45-40.98 9.948-11.212 21.636-19.74 35.059-25.581 13.423-5.845 28.03-8.767 43.822-8.767 15.793 0 30.477 3.081 44.058 9.24a105.774 105.774 0 0 1 35.294 25.82c9.948 11.053 17.689 24.555 23.215 40.506 5.527 15.948 8.29 33.557 8.29 52.824h.003zm-49.272 1.42c0-25.582-5.606-45.875-16.819-60.88-11.212-15-26.766-22.503-46.665-22.503-18.635 0-33.242 7.502-43.822 22.504-10.58 15.004-15.872 34.824-15.872 59.459 0 27.477 5.686 48.4 17.057 62.771 11.37 14.37 26.372 21.557 45.007 21.557 9.16 0 17.53-2.21 25.11-6.632 7.58-4.421 14.053-10.344 19.424-17.767 5.368-7.423 9.474-16.186 12.317-26.293s4.263-20.846 4.263-32.216zm289.938 124.123h-41.69l-33.637-125.543a1119.673 1119.673 0 0 1-7.34-29.136c-2.373-9.948-4.187-17.926-5.45-23.926a1156.906 1156.906 0 0 1-5.448 24.161 994.57 994.57 0 0 1-7.344 29.374l-33.163 125.073h-41.69l-68.22-248.724h48.323l29.371 120.808a595.09 595.09 0 0 1 7.105 29.844c2.211 10.425 3.948 18.638 5.213 24.638l6.158-24.635a4044.692 4044.692 0 0 1 7.582-29.847l33.16-120.808h39.324l33.637 121.282c2.54 9.846 4.985 19.717 7.34 29.608 2.37 9.948 4.345 18.083 5.924 24.4 1.578-6.317 3.395-14.607 5.447-24.873a481.266 481.266 0 0 1 6.87-29.609l29.374-120.808h48.323l-69.169 248.721z" fill="#a6a7a9" fill-rule="nonzero"/></svg>)\n",
    "\n",
    "\n",
    "\n",
    "**Lyndon White**\n",
    " - Research Software Engineer -- Invenia Labs, Cambridge\n",
    " - Technically still PhD Candidate -- The University of Western Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg: @pkg_str\n",
    "pkg\"activate  .\"\n",
    "\n",
    "\n",
    "using TensorFlow\n",
    "using MLDataUtils\n",
    "\n",
    "using MLDatasets\n",
    "using Statistics\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Before TensorFlow\n",
    " \n",
    " - Researchers generally couldn't use Cafe etc as it is not suitably flexible.\n",
    " - One could use Theano, but it is painfully weird\n",
    " - Just write your neural networks by hand, as matrix math\n",
    " - And do your differenciation by hand, first with a blackboard then with more matrix math\n",
    " - While you are at it maybe write your own implementation of gradient descent etc\n",
    " - This was not long ago, I was still doing this in 2014\n",
    " - Julia is a fantasitic language to do this in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Static Graphs\n",
    "\n",
    " - TensorFlow is all about the statc graphs\n",
    " - It is basically a metaprogamming DSL for manipulating static graphs\n",
    " - which are then used to do differencation, and linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ðŸ‘ Easy to manipulate mathematically and easy to think about\n",
    " - It is literally an AST for a language without control flow\n",
    "    - i.e.  a language that is a lot like mathematical notation  \n",
    " - The dervitive of the graph can be calculated  via the chain rule -- generating another graph\n",
    " - Clear seperation of **defintion** from **execution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ðŸ‘Ž Dynamic stuctures are impossible.\n",
    "- A dynamic structure is on in which\n",
    " the network structure differs per input\n",
    "- RNNs have to be statically unrolled to their maximum length\n",
    "- If you want to represent say a tree structured network  (e.g. the work of Bowman, Socher and others for NLP)...  ðŸ˜¿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ðŸ”® Long-term static graphs are probably going away for good.\n",
    "\n",
    " - Dynamic structure makes deep learning more like normnal programming than math\n",
    " - much more flexible\n",
    " - Even TensorFlow is pushing this way wioth TensorFlow 2.0 and TensorFlow for Swift focusing on **TFEager**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4 Types of Nodes, i.e. `Tensors`\n",
    " - **Placeholders:** this is where you put your inputs\n",
    " - **Operations:** theres transform inputs into outputs, they do math\n",
    " - **Variables:** thes are the things you train, they are mutable\n",
    " - **Actions:** These are operations with side effects, like logging (TensorBoard)) and mutating Variable (Optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1) Placeholders\n",
    " \n",
    "  - Use these to declare your networks inputs\n",
    "  \n",
    "```julia\n",
    "x = placeholder(Float64, name=\"x\", shape=[-1, 5])\n",
    "@tf x = placeholder(Float64, name=\"x\", shape=[missing, 5])\n",
    "```\n",
    "\n",
    "When you invoke a network this is done\n",
    "```julia\n",
    "run(sess, output, placeholder_value_dict)\n",
    "```\n",
    "\n",
    "e.g.\n",
    "```julia\n",
    "run(sess, 2x, Dict(x=>[1, 2, 3, 4, 5]')\n",
    "```\n",
    "\n",
    "It is worth noting that you do not have to provide all `placeholder`s on every invocation of your network.\n",
    "Only those on a path leading to your requested output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Automatic Node Naming\n",
    "\n",
    " - Notice before I did `@tf begin ... end`\n",
    " - **This is not at all required**\n",
    " - But it does enable automatic node naming\n",
    " - so `@tf y = sin(x)` actually becomes `y = sin(x; name=\"y\")`\n",
    " - This gives you a good graph in tensorboard, and also better error messages.\n",
    " - Further it lets us look up tensors from the graph by **name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2) Operators\n",
    " \n",
    "  - Use these to declare calculations\n",
    "  \n",
    "```julia\n",
    "z = *(x,y; name=\"z\")\n",
    "@tf z = x*y\n",
    "```\n",
    "\n",
    "When you invoke a network the  can be your outpurs\n",
    "```julia\n",
    "run(sess, output, placeholder_value_dict)\n",
    "```\n",
    "\n",
    "e.g.\n",
    "```julia\n",
    "run(sess, z, Dict(x=>1, y=>2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Functions and Operators\n",
    "\n",
    "Functions mutate **the graph** to introduce **operators**.\n",
    "\n",
    "For example:\n",
    " - `sin(::Float64)` in julia would return a `Float64` that is the answer.\n",
    " - `sin(::Tensor)` introduces a `sin` operation into the graph, and returns a `Tensor` that is a reference to it's output, this could be feed to other operations.\n",
    " \n",
    "The answer to that operation is not computed, until you execute the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = <Tensor y:1 shape=unknown dtype=Float64>\n",
      "run(sess, y, Dict(x => 0.5)) = 0.479425538604203\n"
     ]
    }
   ],
   "source": [
    "sess= Session(Graph())\n",
    "\n",
    "@tf begin\n",
    "    x = placeholder(Float64)\n",
    "    y = sin(x)\n",
    "end\n",
    "\n",
    "@show y\n",
    "\n",
    "@show run(sess, y, Dict(x=>0.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.graph[\"x\"] = <Tensor x:1 shape=unknown dtype=Float64>\n",
      "sess.graph[\"y\"] = <Tensor y:1 shape=unknown dtype=Float64>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.479425538604203"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show sess.graph[\"x\"]\n",
    "@show sess.graph[\"y\"]\n",
    "\n",
    "run(sess, sess.graph[\"y\"], Dict(sess.graph[\"x\"]=>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3) Variables\n",
    "\n",
    "```julia\n",
    "Wout = get_variable(Wout, [128, 128], Float32)\n",
    "@tf Wout = get_variable([128, 128], Float32)\n",
    "```\n",
    "\n",
    "Variables are what are trained.\n",
    "During a `run` of a network, if one of the outputs is an optimizer,\n",
    "it will mutate the variables according to it's loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4) Actions\n",
    " - Technically this is just a kind of operation, with side-effects\n",
    " - Any time a node occurs in the path between the input and the output, it's action is done.\n",
    " - This mean returning the optimizer causes optimization of the parameters to occur\n",
    " \n",
    "```julia\n",
    "opt = train.minimize(train.AdamOptimizer(), net_loss)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lets have an exciting Demo\n",
    "[Link](./Examples.ipynb)\n",
    "\n",
    "![](https://white.ucc.asn.au/posts_assets/Intro%20to%20Machine%20Learning%20with%20TensorFlow.jl_files/Intro%20to%20Machine%20Learning%20with%20TensorFlow.jl_28_0.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lets break that example down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Defining a Custom Activation Function\n",
    "```julia\n",
    "leaky_relu6(x) = 0.01x + nn.relu6(x)\n",
    "```\n",
    "\n",
    " - Trival in the modern day with Flux, etc\n",
    " - When TensorFlow came out, this was insane wizard tricks ðŸ§™\n",
    " - But now we take it for granted.\n",
    " - Note that to do this TensorFlow needed to basically implement a full linear algebra and math library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Building up our layers\n",
    "\n",
    "```julia\n",
    "Zs = [X]\n",
    "for (ii, hlsize) in enumerate(hl_sizes)\n",
    "    Wii = get_variable(\"W_$ii\", [get_shape(Zs[end], 2), hlsize], Float32)\n",
    "    bii = get_variable(\"b_$ii\", [hlsize], Float32)\n",
    "    Zii = leaky_relu6(Zs[end]*Wii + bii)\n",
    "    push!(Zs, Zii)\n",
    "end\n",
    "```\n",
    "\n",
    "Remember what we are actually doing here is mutating the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loss function\n",
    "\n",
    "```julia\n",
    "losses = 0.5(Y .- X).^2\n",
    "loss = reduce_mean(losses) + 0.01reduce_mean(bout.^2)\n",
    "optimizer = train.minimize(train.AdamOptimizer(), loss)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MLDataUtils for training helpers\n",
    "\n",
    "\n",
    "\n",
    " - MLDataUtils is a fantastic julia package full of helpers useful with all ML packages\n",
    " - Use it with TensorFlow, use it with Flux, use it with Knet, etc\n",
    " - `shuffleobs`\n",
    " - `eachbatch`/ `BatchView`\n",
    " - `eachobs`/`obsview`\n",
    " - Various stratified sampling, `oversample`, `undersample`\n",
    " - test/train splitting\n",
    " - feature normalizatin `rescale!`, `center!`\n",
    " - MLLabelUtils for encoding/decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MLDataUtils Example\n",
    "```julia\n",
    "train_obs = shuffleobs(train_images_flat, ObsDim.Last())\n",
    "batches = eachbatch(train_images_flat, 1_000, ObsDim.Last())\n",
    "for (batch_ii, batch_x) in  enumerate(batches)\n",
    "    ...\n",
    "end\n",
    "```\n",
    "\n",
    "More examples:\n",
    "```julia\n",
    "for (batch_x, batch_y) in eachbatch((train_x, train_y), 1000, ObsDim.First())\n",
    "for (batch_x, batch_y) in eachbatch((train_x, train_y), 1000, obsdim=(ObsDim.First(), ObsDim.Last()))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNIST.testtensor() |> typeof = Base.ReinterpretArray{FixedPointNumbers.Normed{UInt8,8},3,UInt8,Array{UInt8,3}}\n",
      "FashionMNIST.testtensor() |> size = (28, 28, 10000)\n",
      "\n",
      "FashionMNIST.testlabels() |> typeof = Array{Int64,1}\n",
      "FashionMNIST.testlabels() |> size = (10000,)\n",
      "\n",
      "typeof(data) = Tuple{Base.ReinterpretArray{FixedPointNumbers.Normed{UInt8,8},3,UInt8,Array{UInt8,3}},Array{Int64,1}}\n",
      "\n",
      "(eachobs(data) |> first) |> typeof = Tuple{Array{FixedPointNumbers.Normed{UInt8,8},2},Int64}\n",
      "nobs(data) = 10000\n"
     ]
    }
   ],
   "source": [
    "@show FashionMNIST.testtensor() |> typeof  \n",
    "@show FashionMNIST.testtensor() |> size\n",
    "println()\n",
    "@show FashionMNIST.testlabels()  |> typeof\n",
    "@show FashionMNIST.testlabels()  |> size\n",
    "\n",
    "println()\n",
    "data = (FashionMNIST.testtensor(), FashionMNIST.testlabels())\n",
    "@show typeof(data)\n",
    "println()\n",
    "@show eachobs(data) |> first |> typeof\n",
    "@show nobs(data);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Complicated Output Layer for HSV Color\n",
    "Saturation and Value are easy, but Hue is angular\n",
    "\n",
    "$$loss =   \\left(y^\\star_{sat} - y_{sat} \\right)^2 + \\left(y^\\star_{val} - y_{val} \\right)^2  + \\frac{1}{2} \\left(\\sin(y^\\star_{hue}) - y_{shue} \\right)^2 + \\frac{1}{2} \\left(\\cos(y^\\star_{hue}) - y_{chue} \\right)^2 $$\n",
    " \n",
    "---\n",
    " \n",
    "<img src=\"./figs/hsv_output_module.png\" width=\"50%\" height=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How do we build this: Prediction & Output\n",
    "\n",
    "```julia\n",
    "# Y_logit size: [missing, 4] \n",
    "Y_sat = nn.sigmoid(Y_logit[:,3])  # range 0:1\n",
    "Y_val = nn.sigmoid(Y_logit[:,4])  # range 0:1\n",
    "\n",
    "Y_shue = tanh(Y_logit[:,1])       # range -1:1 -- like sin\n",
    "Y_chue = tanh(Y_logit[:,2])       # range -1:1 -- like cos\n",
    "\n",
    "# For Output, we want hue angle measured in 0:1 (units of turns)\n",
    "Y_hue_o1 = Ops.atan2(Y_shue, Y_chue)/(2Float32(Ï€))\n",
    "Y_hue_o2 = select(Y_hue_o1 > 0, Y_hue_o1, Y_hue_o1+1) # Wrap around\n",
    "Y_hue = reshape(Y_hue_o2, [-1]) # force shape\n",
    "\n",
    "Y = identity([Y_hue Y_sat Y_val])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How do we build this: Observations & Loss\n",
    "```julia\n",
    "# Obs \n",
    "Y_obs = placeholder(Float32; shape=[-1, 3])\n",
    "Y_obs_hue = Y_obs[:,1]    \n",
    "Y_obs_sat = Y_obs[:,2]\n",
    "Y_obs_val = Y_obs[:,3]\n",
    "\n",
    "Y_obs_shue = sin(Float32(2Ï€) .* Y_obs_hue)\n",
    "Y_obs_chue = cos(Float32(2Ï€) .* Y_obs_hue)\n",
    "\n",
    "\n",
    "# Loss                        \n",
    "loss_hue = 0.5reduce_mean((Y_shue - Y_obs_shue)^2 + (Y_chue - Y_obs_chue)^2))\n",
    "loss_sat = reduce_mean((Y_sat-Y_obs_sat)^2)\n",
    "loss_val = reduce_mean((Y_val-Y_obs_val)^2)\n",
    "\n",
    "loss_total = identity(loss_hue + loss_sat + loss_val)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syntax Overloads\n",
    "\n",
    " - One of the nicest things about julia is how much of the syntax is available to be overloaded\n",
    " - This is used a lot in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overloading hcat & vcat\n",
    "\n",
    "Like in:\n",
    "\n",
    "```julia\n",
    " Y = identity([Y_hue Y_sat Y_val])\n",
    "```\n",
    "\n",
    "\n",
    "So that `[a b]` and `[a; b]` work.\n",
    "vs Base Tensorflow, would have you first make sure everything is the same number of dimensions,\n",
    "then `concat` them,\n",
    "And you couldn't use julia style syntax.\n",
    "\n",
    "https://github.com/malmaud/TensorFlow.jl/blob/7099f05f523556829164aab41eccd394d29df898/src/ops/transformations.jl#L129-L150\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overloading getindex\n",
    "\n",
    "Like in:\n",
    "\n",
    "```julia\n",
    "    Y_sat = nn.sigmoid(Y_logit[:,3])  # range 0:1\n",
    "    Y_val = nn.sigmoid(Y_logit[:,4])  # range 0:1\n",
    "\n",
    "    Y_shue = tanh(Y_logit[:,1])       # range -1:1 -- like sin\n",
    "    Y_chue = tanh(Y_logit[:,2])       # range -1:1 -- like cos\n",
    "```\n",
    "\n",
    "Indexing with slices and ranges is much nicer than `tf.gather` and `tf.gather_nd` and even than `tf.slice`.\n",
    "\n",
    "So that `X[a:b]`, `X[a]`, `X[:, endÃ·2]` etc.\n",
    "\n",
    "https://github.com/malmaud/TensorFlow.jl/blob/master/src/ops/indexing.jl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlow.jl Conventions vs Julia Conventions vs Python TensorFlow Conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Julia**: 1-based indexing   \n",
    "**Python TF**: 0-based indexing  \n",
    "**TensorFlow.jl**: 1-based indexing   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "**Julia:** explicit broadcasting   \n",
    "**Python TF:** implicit broadcasting   \n",
    "**TensorFlow.jl:** implicit or explicit broadcasting  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "**Julia:**  last index at `end`, second last in `end-1`, etc.   \n",
    "**Python TF:** last index at `-1`, second last in `-2`   \n",
    "**TensorFlow.jl** last index at `end`, second last in `end-1`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Julia:**  Operations in Julia ecosystem namespaces. (`SVD` in `LinearAlgebra`, `erfc` in `SpecialFunctions`, `cos` in `Base`)   \n",
    "**Python TF:** All operations in TensorFlow's namespaces (`SVD` in `tf.linalg`, `erfc` in `tf.math`, `cos` in `tf.math`, and all reexported from `tf`)  \n",
    "**TensorFlow.jl**  Existing Julia functions overloaded to call TensorFlow equivalents when called with TensorFlow arguments  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Julia:** Container types are parametrized by number of dimensions and element type   \n",
    "**Python TF:** N/A -- python does not have a parametric type system   \n",
    "**TensorFlow.jl:** Tensors are parametrized by element type.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where are the bits that make TensorFlow.jl work defined?\n",
    "\n",
    "## TensorFlow.jl (Julia)\n",
    " - Nice Things\n",
    " - RNNs\n",
    " - Training / Optimizers\n",
    " \n",
    "## TensorFlow (PyCall)\n",
    " - Gradients\n",
    " - Writing tensorboard events to file\n",
    " \n",
    "## LibTensorFlow (C API)\n",
    " - Operations\n",
    " - Shape Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ðŸ˜¢ BatchNorm\n",
    "\n",
    " - There is a `BatchNorm` op in LibTensorFlow\n",
    " - Actually there are several, for different parts of the Fusing.\n",
    " - to get `BatchNorm` to work, you need to glue these together with the right predeclared variable for state and for reused working memory\n",
    " - This is hundreds (thousands?) of lines of python glue code, that needs to be reimplemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  ðŸ˜¢ Windows Support\n",
    "\n",
    " - I've not tried to get this working in  a while but last time:\n",
    " - Unending segfaults on basic operations.\n",
    " - In theory it should just work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  TFEager\n",
    "## Work In Progress\n",
    "\n",
    " - Jon Malmaud is working on this\n",
    " - Google apparently wants this.\n",
    " - But why? I have a perfectly nice eager NN framework called Flux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dropping the Python Dependency\n",
    " - Python dependency is a nasty hack\n",
    " - It is basically only used for getting gradients.\n",
    " - we actually interact with it primarily by:\n",
    "     - exporting the graph\n",
    "     - running some Python TF on it\n",
    "     - Importing the modified graph back\n",
    "     \n",
    " - We need it for gradients as they are not in the C API\n",
    " - They are coming to the C API, but not ready yet.]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Invenia Labs\n",
    "\n",
    "![](https://www.invenia.ca/wp-content/themes/relish_theme/img/labs-logo.png)\n",
    "\n",
    "## We're hiring\n",
    "### People who know Julia\n",
    "### People who know Machine Learning\n",
    "I have left some fliers about open positions at the entrance."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
