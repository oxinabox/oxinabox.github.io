{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and other tools for ML in Julia\n",
    "\n",
    "**Lyndon White**\n",
    " - Research Software Engineer -- Invenia Labs, Cambridge\n",
    " - Technically still PhD Candidate -- The University of Western Australia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg: @pkg_str\n",
    "pkg\"activate  .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/TensorFlow/IhIhf.ji for TensorFlow [1d978283-2c37-5f34-9a8e-e9c0ece82495]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Loading a new version of TensorFlow.jl for the first time. This initial load can take around 5 minutes as code is precompiled; subsequent usage will only take a few seconds.\n",
      "└ @ TensorFlow ~/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/TensorFlow.jl:3\n",
      "┌ Warning: Module Compat with build ID 259425757446860 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Warning: Module Compat with build ID 259425757446860 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Warning: Loading a new version of TensorFlow.jl for the first time. This initial load can take around 5 minutes as code is precompiled; subsequent usage will only take a few seconds.\n",
      "└ @ TensorFlow /Users/oxinabox/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/TensorFlow.jl:3\n",
      "┌ Info: Precompiling MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "└ @ Base loading.jl:1186\n",
      "┌ Warning: Module Compat with build ID 259425757446860 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/PyCall/GkzkC.ji for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Module Compat with build ID 259425757446860 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Warning: Package TensorFlow does not have Random in its dependencies:\n",
      "│ - If you have TensorFlow checked out for development and have\n",
      "│   added Random as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with TensorFlow\n",
      "│ Loading Random into TensorFlow from project dependency, future warnings for TensorFlow are suppressed.\n",
      "└ @ nothing nothing:840\n",
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/Juno/eE3TV.ji for Juno [e5e0dc1b-0480-54bc-9374-aad01c23163d]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Module MacroTools with build ID 260648583760044 is missing from the cache.\n",
      "│ This may mean MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Warning: Module MacroTools with build ID 260648583760044 is missing from the cache.\n",
      "│ This may mean MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling Media [e89f7d12-3494-54d1-8411-f7d8b9ae1f27]\n",
      "└ @ Base loading.jl:1186\n",
      "┌ Warning: Module MacroTools with build ID 260648583760044 is missing from the cache.\n",
      "│ This may mean MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Warning: Error evaluating expression in Base.__toplevel__:\n",
      "│ module Media\n",
      "│ #= /Users/oxinabox/.julia/packages/Media/ItEPc/src/Media.jl:1 =#\n",
      "│ #= /Users/oxinabox/.julia/packages/Media/ItEPc/src/Media.jl:3 =#\n",
      "│ include(\"dynamic.jl\")\n",
      "│ #= /Users/oxinabox/.julia/packages/Media/ItEPc/src/Media.jl:4 =#\n",
      "│ include(\"system.jl\")\n",
      "│ #= /Users/oxinabox/.julia/packages/Media/ItEPc/src/Media.jl:5 =#\n",
      "│ include(\"compat.jl\")\n",
      "│ #= /Users/oxinabox/.julia/packages/Media/ItEPc/src/Media.jl:7 =#\n",
      "│ function __init__()\n",
      "│     #= /Users/oxinabox/.julia/packages/Media/ItEPc/src/Media.jl:8 =#\n",
      "│     init_compat()\n",
      "│ end\n",
      "│ end\n",
      "└ @ Revise /Users/oxinabox/.julia/packages/Revise/yp5KG/src/parsing.jl:246\n",
      "┌ Warning: Error evaluating expression in Base.__toplevel__:\n",
      "│ module Juno\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:1 =#\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:3 =#\n",
      "│ using Media, Base64, Profile\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:5 =#\n",
      "│ import Media: render\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:7 =#\n",
      "│ export Media, media, @render\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:9 =#\n",
      "│ _active = false\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:11 =#\n",
      "│ isprecompiling() = begin\n",
      "│         #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:11 =#\n",
      "│         ccall(:jl_generating_output, Cint, ()) == 1\n",
      "│     end\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:13 =#\n",
      "│ activate() = begin\n",
      "│         #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:13 =#\n",
      "│         return nothing\n",
      "│     end\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:15 =#\n",
      "│ setactive!(active) = begin\n",
      "│         #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:15 =#\n",
      "│         global _active = active\n",
      "│     end\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:17 =#\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:17 =# Core.:(@doc) \"    isactive()\\n\\nWill return `true` when the current Julia process is connected to a running Juno\\nfrontend.\\n\" isactive() = begin\n",
      "│             #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:23 =#\n",
      "│             _active\n",
      "│         end\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:25 =#\n",
      "│ include(\"types.jl\")\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:26 =#\n",
      "│ include(\"frontend.jl\")\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:27 =#\n",
      "│ include(\"progress.jl\")\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:28 =#\n",
      "│ include(\"user.jl\")\n",
      "│ #= /Users/oxinabox/.julia/packages/Juno/nDCSn/src/Juno.jl:29 =#\n",
      "│ include(\"utils.jl\")\n",
      "│ end\n",
      "└ @ Revise /Users/oxinabox/.julia/packages/Revise/yp5KG/src/parsing.jl:246\n"
     ]
    }
   ],
   "source": [
    "using TensorFlow\n",
    "using TensorFlow: summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Types of Nodes, i.e. `Tensors`\n",
    " - **Placeholders:** this is where you put your inputs\n",
    " - **Operations:** theres transform inputs into outputs, they do math\n",
    " - **Variables:** thes arre the things you train, they are mutable\n",
    " - **Actions:** These are operations with side effects, like logging (TensorBoard)) and mutating Variable (Optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Functions mutate **the graph** to introduce nodes.\n",
    "\n",
    "For example:\n",
    " - `sin(::Float64)` in julia would return a `Float64` that is the answer.\n",
    " - `sin(::Tensor)` introduces a `sin` operation into the graph, and returns a `Tensor` that is a reference to it's output, this could be feed to other operations.\n",
    " \n",
    "The answer to that operation is not computed, until you execute the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = <Tensor y:1 shape=unknown dtype=Float64>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-29 22:23:46.479161: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.479425538604203"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess= Session(Graph())\n",
    "\n",
    "@tf begin\n",
    "    x = placeholder(Float64)\n",
    "    y = sin(x)\n",
    "end\n",
    "\n",
    "@show y\n",
    "\n",
    "run(sess, y, Dict(x=>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Node Naming\n",
    "\n",
    " - Notice before I did `@tf begin ... end`\n",
    " - **This is not at all required**\n",
    " - But it does enable automatic node naming\n",
    " - so `@tf y = sin(x)` actually becomes `y = sin(x; name=\"y\")`\n",
    " - This gives you a good graph in tensorboard, and also better error messages.\n",
    " - Further it lets us look up tensors from the graph by **name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.graph[\"x\"] = <Tensor x:1 shape=unknown dtype=Float64>\n",
      "sess.graph[\"y\"] = <Tensor y:1 shape=unknown dtype=Float64>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.479425538604203"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show sess.graph[\"x\"]\n",
    "@show sess.graph[\"y\"]\n",
    "\n",
    "run(sess, sess.graph[\"y\"], Dict(sess.graph[\"x\"]=>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TensorFlow\n",
    "using MLDataUtils\n",
    "using MLDatasets\n",
    "\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leaky_relu6 (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaky_relu6(x) = 0.01x + nn.relu6(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor has_died:1 shape=() dtype=Bool>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = Session(Graph())\n",
    "\n",
    "# Network Definition\n",
    "@tf begin\n",
    "    X = placeholder(Float32, shape=[-1, 28*28])\n",
    "    \n",
    "    # Network parameters\n",
    "    \n",
    "    hl_sizes = [512, 128, 64, 2, 64, 128, 512]\n",
    "\n",
    "    Zs = [X]\n",
    "    for (ii, hlsize) in enumerate(hl_sizes)\n",
    "        Wii = get_variable(\"W_$ii\", [get_shape(Zs[end], 2), hlsize], Float32)\n",
    "        bii = get_variable(\"b_$ii\", [hlsize], Float32)\n",
    "        Zii = leaky_relu6(Zs[end]*Wii + bii)\n",
    "        push!(Zs, Zii)\n",
    "    end\n",
    "    \n",
    "    Wout = get_variable([get_shape(Zs[end], 2), 28*28], Float32)\n",
    "    bout = get_variable([28*28], Float32)\n",
    "    Y = nn.sigmoid(Zs[end]*Wout + bout)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Z_code = Zs[end÷2] # A name for the coding layer\n",
    "    has_died = reduce_any(reduce_all(Z_code.==0f0, axis=2))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor reduce_2:1 shape=() dtype=Float64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = 0.5(Y .- X).^2\n",
    "loss = reduce_mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = train.minimize(train.AdamOptimizer(), loss)\n",
    "optimizer = train.minimize(train.GradientDescentOptimizer(0.00001), loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run(sess, global_variables_initializer())\n",
    "auto_loss = Float64[]\n",
    "@showprogress for epoch in 1:75\n",
    "    epoch_loss = Float64[]\n",
    "    for batch_x in eachbatch(train_images, 1_000, ObsDim.Last())\n",
    "        loss_o, _ = run(sess, (loss, optimizer), Dict(X=>batch_x'))\n",
    "        push!(epoch_loss, loss_o)\n",
    "    end\n",
    "    push!(auto_loss, mean(epoch_loss))\n",
    "    #println(\"Epoch $epoch loss: $(auto_loss[end])\")\n",
    "    \n",
    "    ### Check to see if it died\n",
    "    if run(sess, has_died, Dict(X=>train_images'))\n",
    "        error(\"Neuron in hidden layer has died, must reinitialize.\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TensorFlow.TFException",
     "evalue": "Tensorflow error: Status: Value for attr 'N' of 0 must be at least minimum 1\n\t; NodeDef: {{node MergeSummary}} = MergeSummary[N=0](); Op<name=MergeSummary; signature=inputs:N*string -> summary:string; attr=N:int,min=1>\n",
     "output_type": "error",
     "traceback": [
      "Tensorflow error: Status: Value for attr 'N' of 0 must be at least minimum 1\n\t; NodeDef: {{node MergeSummary}} = MergeSummary[N=0](); Op<name=MergeSummary; signature=inputs:N*string -> summary:string; attr=N:int,min=1>\n",
      "",
      "Stacktrace:",
      " [1] check_status at /Users/oxinabox/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/core.jl:374 [inlined]",
      " [2] Operation(::TensorFlow.NodeDescription) at /Users/oxinabox/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/core.jl:1043",
      " [3] #merge_summary#281(::Nothing, ::Nothing, ::Function, ::Array{Any,1}) at /Users/oxinabox/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/ops/imported_ops.jl:1988",
      " [4] merge_summary(::Array{Any,1}) at /Users/oxinabox/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/ops/imported_ops.jl:1979",
      " [5] merge_all(::Symbol) at /Users/oxinabox/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/ops/summaries.jl:49",
      " [6] merge_all() at /Users/oxinabox/Documents/talks/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/ops/summaries.jl:48",
      " [7] top-level scope at In[12]:3"
     ]
    }
   ],
   "source": [
    "# Create a summary writer\n",
    "summary_writer = TensorFlow.summary.FileWriter(mkpath(\"logs\"))\n",
    "run(session, TensorFlow.summary.merge_all())\n",
    "write(summary_writer, , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/Invenia`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `git@gitlab.invenia.ca:invenia/PackageRegistry.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Conda ── v1.2.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Compat ─ v1.5.0\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/Documents/talks/JuliaDeepLearningMeetupLondon2019/Project.toml`\n",
      " \u001b[90m [cc2ba9b6]\u001b[39m\u001b[92m + MLDataUtils v0.4.0\u001b[39m\n",
      " \u001b[90m [1d978283]\u001b[39m\u001b[31m ? TensorFlow v0.11.0+ [`dev/TensorFlow`] ⇒ v0.12.0 [`dev/TensorFlow`]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/Documents/talks/JuliaDeepLearningMeetupLondon2019/Manifest.toml`\n",
      " \u001b[90m [324d7699]\u001b[39m\u001b[92m + CategoricalArrays v0.5.2\u001b[39m\n",
      " \u001b[90m [34da2185]\u001b[39m\u001b[93m ↑ Compat v1.4.0 ⇒ v1.5.0\u001b[39m\n",
      " \u001b[90m [8f4d0f93]\u001b[39m\u001b[93m ↑ Conda v1.1.1 ⇒ v1.2.0\u001b[39m\n",
      " \u001b[90m [a93c6f00]\u001b[39m\u001b[92m + DataFrames v0.17.0\u001b[39m\n",
      " \u001b[90m [9a8bc11e]\u001b[39m\u001b[92m + DataStreams v0.4.1\u001b[39m\n",
      " \u001b[90m [82899510]\u001b[39m\u001b[92m + IteratorInterfaceExtensions v0.1.1\u001b[39m\n",
      " \u001b[90m [7f8f8fb0]\u001b[39m\u001b[92m + LearnBase v0.2.2\u001b[39m\n",
      " \u001b[90m [9920b226]\u001b[39m\u001b[92m + MLDataPattern v0.5.0\u001b[39m\n",
      " \u001b[90m [cc2ba9b6]\u001b[39m\u001b[92m + MLDataUtils v0.4.0\u001b[39m\n",
      " \u001b[90m [66a33bbf]\u001b[39m\u001b[92m + MLLabelUtils v0.5.1\u001b[39m\n",
      " \u001b[90m [dbb5928d]\u001b[39m\u001b[92m + MappedArrays v0.2.1\u001b[39m\n",
      " \u001b[90m [3783bdb8]\u001b[39m\u001b[92m + TableTraits v0.4.1\u001b[39m\n",
      " \u001b[90m [bd369af6]\u001b[39m\u001b[92m + Tables v0.1.14\u001b[39m\n",
      " \u001b[90m [1d978283]\u001b[39m\u001b[31m ? TensorFlow v0.11.0+ [`dev/TensorFlow`] ⇒ v0.12.0 [`dev/TensorFlow`]\u001b[39m\n",
      " \u001b[90m [ea10d353]\u001b[39m\u001b[92m + WeakRefStrings v0.5.4\u001b[39m\n",
      " \u001b[90m [9fa8497b]\u001b[39m\u001b[92m + Future \u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Conda → `~/.julia/packages/Conda/CpuvI/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "pkg\"add MLDataUtils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invenia Labs\n",
    "## We're hiring\n",
    "### People who know Julia\n",
    "### People who know Machine Learning\n",
    "I have left some fliers about open positions at the entrance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
