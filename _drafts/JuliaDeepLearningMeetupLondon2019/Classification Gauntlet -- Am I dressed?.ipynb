{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Pkg: @pkg_str\n",
    "pkg\"activate .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/MLDatasets/9CUQK.ji for MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/MLDataUtils/CQWB9.ji for MLDataUtils [cc2ba9b6-d476-5e6d-8eaf-a92d5412d41d]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/LIBSVM/3eWAI.ji for LIBSVM [b1bec4e5-fd48-53fe-b0cb-9723c09d164b]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/DecisionTree/pEDeB.ji for DecisionTree [7806a523-6efd-50cb-b5f6-3fa6f1930dbb]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/Flux/QdkVy.ji for Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/oxinabox/.julia/compiled/v1.1/TensorFlow/IhIhf.ji for TensorFlow [1d978283-2c37-5f34-9a8e-e9c0ece82495]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Loading a new version of TensorFlow.jl for the first time. This initial load can take around 5 minutes as code is precompiled; subsequent usage will only take a few seconds.\n",
      "└ @ TensorFlow ~/Documents/oxinabox.github.io/_drafts/JuliaDeepLearningMeetupLondon2019/dev/TensorFlow/src/TensorFlow.jl:3\n"
     ]
    }
   ],
   "source": [
    "using MLDatasets\n",
    "using MLDataUtils\n",
    "using Statistics\n",
    "using LIBSVM\n",
    "using DecisionTree\n",
    "using Flux\n",
    "using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FashionMNIST\n",
    "https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "![](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a programmer, I clearly just randomly grab two items of clothing out of my wardrobe without concern for if they would leaving me appropriately covered.\n",
    "\n",
    "I would like a ML system that looks at images of my two items of clothing,\n",
    "and tells me if they are going to cover me.\n",
    "That means a dress, or a top and trousers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appropriately_dressed (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function appropriately_dressed(clothing_items...)\n",
    "    3 ∈ clothing_items && return true  # A dress is both top and bottoms\n",
    "    \n",
    "    # need trousers and a top of some kind\n",
    "    return 1 ∈ clothing_items && length(intersect(clothing_items,(0, 2, 4, 6))) > 0 \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a dataset\n",
    "We are going to generate a dataset,\n",
    "by taking two copies of FashionMNIST,\n",
    "shuffling them, and drawing them off in pairs,\n",
    "labelling each with a suitable label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_pants_dataset (generic function with 2 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_pants_dataset(data, max_obs=Inf)\n",
    "    combination_images = Vector{Vector{Float32}}()\n",
    "    is_dressed_labels = Vector{Bool}()\n",
    "    for (img1, lbl1) in eachobs(shuffleobs(data)), (img2, lbl2) in eachobs(shuffleobs(data))\n",
    "        push!(combination_images, [img1[:]; img2[:]])\n",
    "        push!(is_dressed_labels,  appropriately_dressed(lbl1, lbl2))\n",
    "        if length(is_dressed_labels) >= max_obs\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    return combination_images, is_dressed_labels\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(last, eachobs(train_data)) = 0.49405\n",
      "mean(last, eachobs(test_data)) = 0.489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.489"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "#Random.seed!(4)\n",
    "Random.seed!(14)\n",
    "\n",
    "\n",
    "train_data = generate_pants_dataset((FashionMNIST.traintensor(), FashionMNIST.trainlabels()), 20_000)\n",
    "@show mean(last, eachobs(train_data))\n",
    "\n",
    "test_data = generate_pants_dataset((FashionMNIST.testtensor(), FashionMNIST.testlabels()), 1_000);\n",
    "@show mean(last, eachobs(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a Balanced Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobs(balanced_train_data) = 19762\n",
      "mean(last, eachobs(balanced_train_data)) = 0.5\n"
     ]
    }
   ],
   "source": [
    "balanced_train_data = undersample(last, train_data);\n",
    "\n",
    "@show nobs(balanced_train_data)\n",
    "@show mean(last, eachobs(balanced_train_data));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_decision_tree (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function demo_decision_tree(train_data, test_data)\n",
    "    train_features = collect(reduce(hcat, train_data[1])')\n",
    "    train_labels = collect(train_data[2])\n",
    "\n",
    "    # train full-tree classifier\n",
    "    model = build_tree(train_labels, train_features)\n",
    "    # prune tree: merge leaves having >= 90% combined purity (default: 100%)\n",
    "    model = prune_tree(model, 0.9)\n",
    "\n",
    "\n",
    "    test_features = collect(reduce(hcat, test_data[1])')\n",
    "    test_labels = collect(test_data[2]);\n",
    "    classes = apply_tree(model, test_features)\n",
    "    acc = mean(test_labels .== classes)\n",
    "    @show acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.972\n",
      "  7.792420 seconds (7.79 M allocations: 667.818 MiB, 3.72% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_decision_tree(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.974\n",
      "  7.639289 seconds (6.37 M allocations: 629.928 MiB, 3.04% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.974"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_decision_tree(balanced_train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_random_forest (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function demo_random_forest(train_data, test_data)\n",
    "    train_features = collect(reduce(hcat, train_data[1])')\n",
    "    train_labels = collect(train_data[2])\n",
    "\n",
    "    model = build_forest(train_labels, train_features)\n",
    "\n",
    "    test_features = collect(reduce(hcat, test_data[1])')\n",
    "    test_labels = collect(test_data[2]);\n",
    "    classes = apply_forest(model, test_features)\n",
    "    acc = mean(test_labels .== classes)\n",
    "    @show acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.983\n",
      "  4.451049 seconds (5.04 M allocations: 1.376 GiB, 14.84% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_random_forest(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.983\n",
      "  2.008578 seconds (135.18 k allocations: 1.093 GiB, 9.08% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_random_forest(balanced_train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_libsvm (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function demo_libsvm(train_data, test_data)\n",
    "    train_features = reduce(hcat, train_data[1])\n",
    "    train_labels = train_data[2]\n",
    "\n",
    "    model = svmtrain(train_features, train_labels)\n",
    "\n",
    "    test_features = reduce(hcat, test_data[1])\n",
    "    test_labels = test_data[2];\n",
    "\n",
    "    classes, probs = svmpredict(model, test_features)\n",
    "    acc = mean(test_labels .== classes)\n",
    "    @show acc\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.972\n",
      "364.577990 seconds (3.72 M allocations: 917.620 MiB, 0.06% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_libsvm(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.971\n",
      "360.541369 seconds (1.06 M allocations: 762.905 MiB, 0.06% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.971"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_libsvm(balanced_train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_tf (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tensorflow_model(in_size = 1568)\n",
    "    sess = Session(Graph())\n",
    "\n",
    "    leaky_relu6(x) = 0.01x + nn.relu6(x)\n",
    "\n",
    "    # Network Definition\n",
    "    @tf begin\n",
    "        X = placeholder(Float32, shape=[-1, in_size])\n",
    "\n",
    "        # Network parameters\n",
    "        hl_sizes = [512, 128, 64]\n",
    "\n",
    "        Zs = [X]\n",
    "        for (ii, hlsize) in enumerate(hl_sizes)\n",
    "            Wii = get_variable(\"W_$ii\", [get_shape(Zs[end], 2), hlsize], Float32)\n",
    "            bii = get_variable(\"b_$ii\", [hlsize], Float32)\n",
    "            Zii = leaky_relu6(Zs[end]*Wii + bii)\n",
    "            push!(Zs, Zii)\n",
    "        end\n",
    "\n",
    "        Wout = get_variable([get_shape(Zs[end], 2), 1], Float32)\n",
    "        bout = get_variable([1], Float32)\n",
    "        Y_logits = Zs[end]*Wout + bout\n",
    "        \n",
    "        Y_mat = nn.sigmoid(Y_logits)\n",
    "        Y_pred = dropdims(Y_mat; dims=[2]) #drop first dimention\n",
    "        \n",
    "        Y_target = placeholder(Float32, shape=[-1])\n",
    "        loss = nn.sigmoid_cross_entropy_with_logits(;logits=Y_pred, targets=Y_target)\n",
    "        mean_loss = mean(loss)\n",
    "        optimizer = TensorFlow.train.minimize(train.AdamOptimizer(), loss)\n",
    "    end \n",
    "    run(sess, global_variables_initializer())\n",
    "\n",
    "    return (sess, optimizer)\n",
    "end\n",
    "\n",
    "function demo_tf(train_data, test_data)\n",
    "    sess, opt = tensorflow_model()\n",
    "    \n",
    "    train_features = collect(reduce(hcat, train_data[1])')\n",
    "    train_labels = collect(train_data[2])\n",
    "    \n",
    "    for epoch in 1:50\n",
    "        run(sess, opt, Dict(\n",
    "            sess.graph[\"X\"] => train_features,\n",
    "            sess.graph[\"Y_target\"] => train_labels\n",
    "        ))\n",
    "    end\n",
    "\n",
    "    test_features = collect(reduce(hcat, test_data[1])')\n",
    "    test_labels = collect(test_data[2]);\n",
    "    \n",
    "    classes = run(sess, sess.graph[\"Y_pred\"] > 0.5, Dict(\n",
    "            sess.graph[\"X\"] => test_features\n",
    "        ))\n",
    "    @show mean(classes)\n",
    "    acc = mean(test_labels .== classes)\n",
    "    @show acc\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(classes) = 0.482\n",
      "acc = 0.963\n",
      " 69.198244 seconds (7.48 M allocations: 6.587 GiB, 1.75% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.963"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_tf(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(classes) = 0.483\n",
      "acc = 0.962\n",
      " 66.390082 seconds (6.79 M allocations: 6.481 GiB, 1.56% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.962"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_tf(balanced_train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_flux (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function flux_model(in_size = 1568)\n",
    "    leaky_relu6(x) = 0.01x + clamp(x, 0, 6)\n",
    "\n",
    "    return Chain(\n",
    "        Dense(in_size, 512, leaky_relu6), \n",
    "        Dense(512, 128, leaky_relu6),\n",
    "        Dense(128, 64, leaky_relu6), \n",
    "        Dense(64, 1),\n",
    "        vec\n",
    "    )\n",
    "    \n",
    "end\n",
    "\n",
    "function demo_flux(train_data, test_data)\n",
    "    mdl = flux_model()\n",
    "    \n",
    "    features = reduce(hcat, first(train_data))\n",
    "    labels = Float32.(last(train_data))\n",
    "    \n",
    "    Flux.train!(\n",
    "        params(mdl),\n",
    "        Iterators.repeated((features, labels), 50), # 50 epochs\n",
    "        Flux.ADAM()\n",
    "    ) do xs, ys # This block repressents 1 epoch\n",
    "        mean(Flux.logitbinarycrossentropy.(mdl(xs), ys))\n",
    "    end\n",
    "    \n",
    "    test_features, test_labels = test_data\n",
    "    \n",
    "    probs = map(first∘Flux.data∘mdl, test_features)\n",
    "    classes = probs .> 0\n",
    "    @show mean(classes)\n",
    "    acc = mean(test_labels .== classes)\n",
    "    @show acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(classes) = 0.49\n",
      "acc = 0.983\n",
      "2065.326004 seconds (13.86 M allocations: 44.192 GiB, 1.85% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_flux(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(classes) = 0.499\n",
      "acc = 0.98\n",
      "1857.211644 seconds (883.72 k allocations: 43.037 GiB, 1.75% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time demo_flux(balanced_train_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
